Normalising tot log maps, mean: 23.118974685668945, std: 1.2879376411437988
Normalising gas log maps, mean: 22.003015518188477, std: 1.309154748916626
Normalising vcdm log maps, mean: 145.90553283691406, std: 88.52458190917969
Normalising tot log maps, mean: 23.118974685668945, std: 1.2879376411437988
Normalising gas log maps, mean: 22.003015518188477, std: 1.309154748916626
Normalising vcdm log maps, mean: 145.90553283691406, std: 88.52458190917969
Restoring states from the checkpoint path at /mnt/home/mliu1/FMbaseline_final2/lightning_logs/o6p5mo2p/checkpoints/last.ckpt
Traceback (most recent call last):
  File "/mnt/home/mliu1/PUBLIC/FM_encode/star_flow.py", line 192, in <module>
    model_unet, trainer_unet = train_flow_matching_model(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/PUBLIC/FM_encode/star_flow.py", line 85, in train_flow_matching_model
    trainer.fit(model, data_module, ckpt_path=ckpt_path)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 409, in _restore_modules_and_callbacks
    self.restore_model()
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 286, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for FlowMatchingModel:
	Missing key(s) in state_dict: "scalar_field.dm_encoder.0.weight", "scalar_field.dm_encoder.0.bias", "scalar_field.dm_encoder.4.weight", "scalar_field.dm_encoder.4.bias", "scalar_field.vdm_encoder.0.weight", "scalar_field.vdm_encoder.0.bias", "scalar_field.vdm_encoder.4.weight", "scalar_field.vdm_encoder.4.bias", "resnet_branch.conv1.weight", "resnet_branch.gn1.weight", "resnet_branch.gn1.bias", "resnet_branch.layer1.0.gn1.weight", "resnet_branch.layer1.0.gn1.bias", "resnet_branch.layer1.0.conv1.weight", "resnet_branch.layer1.0.gn2.weight", "resnet_branch.layer1.0.gn2.bias", "resnet_branch.layer1.0.conv2.weight", "resnet_branch.layer1.1.gn1.weight", "resnet_branch.layer1.1.gn1.bias", "resnet_branch.layer1.1.conv1.weight", "resnet_branch.layer1.1.gn2.weight", "resnet_branch.layer1.1.gn2.bias", "resnet_branch.layer1.1.conv2.weight", "resnet_branch.layer2.0.gn1.weight", "resnet_branch.layer2.0.gn1.bias", "resnet_branch.layer2.0.conv1.weight", "resnet_branch.layer2.0.gn2.weight", "resnet_branch.layer2.0.gn2.bias", "resnet_branch.layer2.0.conv2.weight", "resnet_branch.layer2.0.shortcut.weight", "resnet_branch.layer2.1.gn1.weight", "resnet_branch.layer2.1.gn1.bias", "resnet_branch.layer2.1.conv1.weight", "resnet_branch.layer2.1.gn2.weight", "resnet_branch.layer2.1.gn2.bias", "resnet_branch.layer2.1.conv2.weight", "resnet_branch.layer3.0.gn1.weight", "resnet_branch.layer3.0.gn1.bias", "resnet_branch.layer3.0.conv1.weight", "resnet_branch.layer3.0.gn2.weight", "resnet_branch.layer3.0.gn2.bias", "resnet_branch.layer3.0.conv2.weight", "resnet_branch.layer3.0.shortcut.weight", "resnet_branch.layer3.1.gn1.weight", "resnet_branch.layer3.1.gn1.bias", "resnet_branch.layer3.1.conv1.weight", "resnet_branch.layer3.1.gn2.weight", "resnet_branch.layer3.1.gn2.bias", "resnet_branch.layer3.1.conv2.weight", "resnet_branch.fc.1.weight", "resnet_branch.fc.1.bias", "resnet_branch.fc.3.weight", "resnet_branch.fc.3.bias".
	Unexpected key(s) in state_dict: "scalar_field.time_mlp.0.weight", "scalar_field.time_mlp.0.bias", "scalar_field.time_mlp.2.weight", "scalar_field.time_mlp.2.bias".
	size mismatch for scalar_field.condition_mlp.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([192, 96]).
	size mismatch for scalar_field.condition_mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for scalar_field.condition_mlp.2.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([96, 192]).
	size mismatch for scalar_field.condition_mlp.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for scalar_field.enc1.film1.linear.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([512, 96]).
	size mismatch for scalar_field.enc1.film2.linear.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([512, 96]).
	size mismatch for scalar_field.enc2.film1.linear.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([512, 96]).
	size mismatch for scalar_field.enc2.film2.linear.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([512, 96]).
	size mismatch for scalar_field.enc3.film1.linear.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1024, 96]).
	size mismatch for scalar_field.enc3.film2.linear.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1024, 96]).
	size mismatch for scalar_field.bottleneck_film.linear.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1024, 96]).
	size mismatch for scalar_field.dec3.film1.linear.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1024, 96]).
	size mismatch for scalar_field.dec3.film2.linear.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1024, 96]).
	size mismatch for scalar_field.dec2.film1.linear.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([512, 96]).
	size mismatch for scalar_field.dec2.film2.linear.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([512, 96]).
	size mismatch for scalar_field.dec1.film1.linear.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([256, 96]).
	size mismatch for scalar_field.dec1.film2.linear.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([256, 96]).
