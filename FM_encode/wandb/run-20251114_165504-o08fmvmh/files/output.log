Normalising tot log maps, mean: 23.118974685668945, std: 1.2879376411437988
Normalising gas log maps, mean: 22.003015518188477, std: 1.309154748916626
Normalising vcdm log maps, mean: 145.90553283691406, std: 88.52458190917969
Normalising tot log maps, mean: 23.118974685668945, std: 1.2879376411437988
Normalising gas log maps, mean: 22.003015518188477, std: 1.309154748916626
Normalising vcdm log maps, mean: 145.90553283691406, std: 88.52458190917969
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name          | Type            | Params | Mode
----------------------------------------------------------
0 | scalar_field  | UNetScalarField | 63.3 M | train
1 | resnet_branch | ResNetBranch    | 8.3 M  | train
----------------------------------------------------------
71.6 M    Trainable params
0         Non-trainable params
71.6 M    Total params
286.396   Total estimated model params size (MB)
168       Modules in train mode
0         Modules in eval mode
Epoch 0:   0%|                                                                                                                                   | 0/2 [00:00<?, ?it/s]
/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Traceback (most recent call last):
  File "/mnt/home/mliu1/PUBLIC/FM_encode/star_flow.py", line 193, in <module>
    model_unet, trainer_unet = train_flow_matching_model(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/PUBLIC/FM_encode/star_flow.py", line 87, in train_flow_matching_model
    trainer.fit(model, data_module)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 185, in run
    closure()
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/PUBLIC/FM_encode/module.py", line 218, in training_step
    predicted_velocity = self(input_field, t, params, embed)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/PUBLIC/FM_encode/module.py", line 162, in forward
    return self.scalar_field(x, t, params, embed)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/PUBLIC/FM_encode/models.py", line 271, in forward
    x = self.dec1(x, combined_embed)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/PUBLIC/FM_encode/models.py", line 156, in forward
    h = self.norm1(x)
        ^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/modules/normalization.py", line 313, in forward
    return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/home/mliu1/env/lib/python3.11/site-packages/torch/nn/functional.py", line 2960, in group_norm
    return torch.group_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 79.32 GiB of which 1.98 GiB is free. Including non-PyTorch memory, this process has 77.33 GiB memory in use. Of the allocated memory 70.31 GiB is allocated by PyTorch, and 6.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
